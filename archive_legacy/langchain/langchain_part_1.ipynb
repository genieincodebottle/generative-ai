{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXSRMUf+EE1lpDpgqqw0UE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-v19XlsqP7mI"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["##**Install Langchain and Google Gemini related libraries**"],"metadata":{"id":"6dNa79_nt5dZ"}},{"cell_type":"code","source":["!pip install -q -U langchain\n","!pip install -q -U google-generativeai langchain-google-genai"],"metadata":{"id":"r76L6X4AQJEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Get Gemini Key from Secrets **\n","Set GEMINI_KEY secret key at Google Colab and get that here to runn Google Gemini LLM. You can get Google Gemini Key from following link https://makersuite.google.com/app/apikey"],"metadata":{"id":"VkmAUJVzuG2T"}},{"cell_type":"code","source":["from google.colab import userdata\n","GOOGLE_API_KEY = userdata.get('GEMINI_KEY')"],"metadata":{"id":"FXFDa9vmuCb4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Run Simple LLM Prompt**"],"metadata":{"id":"NiL4K9ZMul9O"}},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain\n","\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are world class technical documentation writer.\"),\n","    (\"user\", \"{input}\")\n","])\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=True)\n","\n","chain = prompt | llm"],"metadata":{"id":"UPxFgUgQQ9jQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resp = chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n","print(resp)"],"metadata":{"id":"va7Kp1e4SNi_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Run LLM with OutputParser**"],"metadata":{"id":"WudaEJd_usjV"}},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","\n","output_parser = StrOutputParser()"],"metadata":{"id":"y4vTv_nvSdrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain = prompt | llm | output_parser"],"metadata":{"id":"Cu4LMHd4Slil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resp = chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n","print(resp)"],"metadata":{"id":"geBneWiCSrmb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Run Retrieval Augumented Generation with LangChain and Gemini**\n","We are using beautifulsoup4 to scrap web data and use that as external source to augment to LLM"],"metadata":{"id":"cfvP9otHu0kR"}},{"cell_type":"code","source":["!pip install beautifulsoup4"],"metadata":{"id":"OXkkqpMCS4LX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.document_loaders import WebBaseLoader\n","loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n","\n","docs = loader.load()"],"metadata":{"id":"URh6tt9xTDln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q -U sentence-transformers\n","from langchain.embeddings import HuggingFaceEmbeddings\n","# Using HuggingFace embeddings\n","embeddings = HuggingFaceEmbeddings()"],"metadata":{"id":"Jn_-6QqJTNxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install faiss-gpu"],"metadata":{"id":"BJPV_wYwTyqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.vectorstores import FAISS\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","\n","text_splitter = RecursiveCharacterTextSplitter()\n","documents = text_splitter.split_documents(docs)\n","vector = FAISS.from_documents(documents, HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))"],"metadata":{"id":"oDU7BlGBT9R3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains.combine_documents import create_stuff_documents_chain\n","\n","prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n","\n","<context>\n","{context}\n","</context>\n","\n","Question: {input}\"\"\")\n","\n","document_chain = create_stuff_documents_chain(llm, prompt)"],"metadata":{"id":"b79l68afUlCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.documents import Document\n","\n","document_chain.invoke({\n","    \"input\": \"how can langsmith help with testing?\",\n","    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n","})"],"metadata":{"id":"mZSsIj_TU7Pp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import create_retrieval_chain\n","\n","retriever = vector.as_retriever()\n","retrieval_chain = create_retrieval_chain(retriever, document_chain)"],"metadata":{"id":"TLVz-6TyVNq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n","print(response[\"answer\"])"],"metadata":{"id":"JDEqlpnoVham"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Run Converstation Retrieval chain with history**\n","The provided way in LangChain quickstart guide throws error when we use Google Gemini with LangChain. There might be support issue of Langchain with Google Gemini. This is alternative method."],"metadata":{"id":"eXf0kuDavMI7"}},{"cell_type":"code","source":["from langchain_community.vectorstores import FAISS\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n","documents = text_splitter.split_documents(docs)\n","vector = FAISS.from_documents(documents, HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L12-v2'))"],"metadata":{"id":"ZQH_6Wr2JfEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.chains import ConversationalRetrievalChain\n","\n","# Connect query to FAISS index using a retriever\n","retriever = vector.as_retriever()\n","\n","qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever,return_source_documents=True)\n","print(retriever)"],"metadata":{"id":"kigtu9OEIkBx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","chat_history = []\n","while True:\n","    query = input('Prompt: ')\n","    result = qa_chain({'question': query, 'chat_history': chat_history})\n","    print('Answer: ' + result['answer'] + '\\n')\n","    chat_history.append((query, result['answer']))"],"metadata":{"id":"5c7jTpIhIqAE"},"execution_count":null,"outputs":[]}]}