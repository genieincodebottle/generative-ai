{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# How to Use Ollama at Google Colab#  \n",
        " Using Ollama with Google Colab can be tricky! Sometimes our local systems lack the memory or CPU power needed for open-source LLMs. Google Colab offers free GPUs. Here's how to set it up:\n",
        "\n",
        "1ï¸âƒ£ !pip install colab-xterm\n",
        "\n",
        "2ï¸âƒ£ %load_ext colabxterm\n",
        "\n",
        "ðŸ”§ The purpose of these commands is to set up a terminal environment within the Colab notebook. This can be useful for running command-line tools or interacting with the system in ways that aren't easily done through the standard Colab interface.\n",
        "\n",
        "3ï¸âƒ£ !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "4ï¸âƒ£ %xterm (This opens a terminal in Colab. Run: ollama serve &)\n",
        "\n",
        "5ï¸âƒ£ !ollama pull llama3.1 > /dev/null 2>&1\n",
        "\n",
        "With these commands, you can access Ollama-based LLMs/models on Google Colab seamlessly. Happy coding! ðŸ’»âœ¨"
      ],
      "metadata": {
        "id": "jfDt05fp1eqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's break it down the following cell codes:\n",
        "\n",
        "> !pip install colab-xterm\n",
        "\n",
        "The ! at the beginning allows you to run shell commands in a Colab notebook cell.\n",
        "This command installs the colab-xterm package using pip, Python's package installer.\n",
        "colab-xterm is a package that provides an Xterm terminal emulator for Google Colab notebooks.\n",
        "\n",
        "> %load_ext colabxterm:\n",
        "\n",
        "This is an IPython magic command (indicated by the % symbol).\n",
        "It loads the colabxterm extension into the current Jupyter notebook environment.\n",
        "Once loaded, this extension allows you to use an interactive terminal within your Colab notebook.\n",
        "\n",
        "The purpose of these commands is to set up a terminal environment within the Colab notebook. This can be useful for running command-line tools or interacting with the system in ways that aren't easily done through the standard Colab interface."
      ],
      "metadata": {
        "id": "h0kmFirY1oZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm #https://pypi.org/project/colab-xterm/\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "1tgc1KnW1nyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ollama Installation Script\n",
        "\n",
        "This script installs Ollama, a powerful open-source LLM, on your system. Follow the instructions below to ensure a successful installation.\n",
        "\n",
        "## Installation Steps\n",
        "\n",
        "Run the Installation Command\n",
        "\n",
        "Open your terminal and execute the following command:\n",
        "\n",
        "\n",
        "> !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "## What the Command Does\n",
        "\n",
        "curl -fsSL https://ollama.com/install.sh: Downloads the installation script from the Ollama website.\n",
        "\n",
        "| sh: Pipes the downloaded script to the shell for execution."
      ],
      "metadata": {
        "id": "9hFuGXWq2W6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "eKR2hVeoKP9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# %xterm Command in Google Colab\n",
        "The %xterm command is used to open an interactive terminal session within a Google Colab notebook.\n",
        "\n",
        "This allows you to execute command-line tools and interact with the system in ways that aren't easily done through the standard Colab interface."
      ],
      "metadata": {
        "id": "lyrcXqJ52_bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "y8uMIKoUiQ7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# !ollama pull llama3.1 > /dev/null 2>&1 Command\n",
        "\n",
        "This command is used to pull the llama3.1 model using Ollama while suppressing the output. Here's a breakdown of what each part of the command does:\n",
        "\n",
        "## Command Breakdown\n",
        "!ollama pull llama3.1\n",
        "\n",
        "(1) !: This indicates that the command is a shell command to be executed from within a Jupyter notebook or Google Colab.\n",
        "\n",
        "(2) ollama pull llama3.1: This part of the command uses Ollama to download (pull) the llama3.1 model. ollama is the command-line interface, pull is the action to download a model, and llama3.1 specifies the model to be downloaded.\n",
        "> /dev/null 2>&1\n",
        "\n",
        "> /dev/null: Redirects the standard output (stdout) to /dev/null, a special file that discards all data written to it. This suppresses the output of the command.\n",
        "\n",
        "> 2>&1: Redirects the standard error (stderr) to the same location as the standard output. This ensures that any error messages are also discarded.\n",
        "Purpose\n",
        "\n",
        "The purpose of this command is to download the llama3.1 model using Ollama without displaying any output or error messages in the terminal or notebook. This is useful when you want to perform the operation silently, without cluttering the interface with output text."
      ],
      "metadata": {
        "id": "gObowt7K3S0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull llama3.1 > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "-gonJ3tiiY7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required library"
      ],
      "metadata": {
        "id": "0ifi-FiC3qf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchain_community langchain-ollama"
      ],
      "metadata": {
        "id": "O5RXAVT9_XW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Ollama based Llam3.1 model and langchain to get the LLM response"
      ],
      "metadata": {
        "id": "hhxktS2n3xAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"You are an assistant for question-answering tasks.\n",
        "\n",
        "    If you don't know the answer, just say that you don't know.\n",
        "\n",
        "    Use three sentences maximum and keep the answer concise:\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=\"llama3.1\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "response = chain.invoke({\"question\": \"Why should we learn GenAI?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "5cpGA_ayKo4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code snippet is used in a Jupyter notebook environment to display a formatted Markdown string. Here's a breakdown of each part of the code:"
      ],
      "metadata": {
        "id": "viwfWc4f4Gm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "print(display(Markdown(response)))"
      ],
      "metadata": {
        "id": "mQH05AUzS3WG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}