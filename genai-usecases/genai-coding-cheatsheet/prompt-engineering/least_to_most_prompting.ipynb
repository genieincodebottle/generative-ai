{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/drive/19PVturaEBDbEq9UqTfWm5-6FhqeVMNgk?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "### 🔄 Self-Consistency - Prompt Engineering\n",
        "\n",
        "Self-Consistency is a method to improve the reliability of language model outputs.\n",
        "\n",
        "### Key points:\n",
        "\n",
        "* 🔑 **Core concept:** Generate multiple independent solutions and select the most consistent one.\n",
        "\n",
        "* ⚙️ **Process:**\n",
        "  * Prompt the model multiple times for the same task\n",
        "  * Collect various reasoning paths and answers\n",
        "  * Choose the most common or consistent answer\n",
        "\n",
        "* 🌟 **Advantages:**\n",
        "  * Improves accuracy, especially for complex tasks\n",
        "  * Reduces impact of occasional errors or biases\n",
        "\n",
        "* 💼 **Applications:** Mathematical problem-solving, logical reasoning, decision-making.\n",
        "\n",
        "* 🚀 **Implementation:**\n",
        "  * Use temperature settings to introduce variability\n",
        "  * Prompt for full reasoning chains, not just final answers\n",
        "\n",
        "* **Evaluation:** Can use voting mechanisms or more sophisticated consistency measures.\n",
        "\n",
        "* ⚖️ **Challenges:**\n",
        "  * Increased computational cost\n",
        "  * Handling genuinely ambiguous problems\n",
        "\n",
        "* 🔄 **Variations:** Can be combined with other techniques like Chain of Thought or Tree of Thoughts."
      ],
      "metadata": {
        "id": "Y2eqHW0TK87s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain-groq==0.2.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI4D1HL-LKaP",
        "outputId": "263c00d5-a34d-4920-ebf3-711297d41075"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "dfHHptAFLMwj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass"
      ],
      "metadata": {
        "id": "eZJGDTIMLOnP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔑 Provide Groq API Key\n",
        "\n",
        "- [Groq API Key](https://console.groq.com/keys)\n",
        "\n"
      ],
      "metadata": {
        "id": "rQrlkg_bLRZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8sLK8uLTht",
        "outputId": "5ea931dc-548c-452f-ea9c-dfacdd665d74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "0os_AIehLVh1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are an AI that can break down complex problems into simpler sub-problems.\"),\n",
        "        (\"human\", \"\"\"Break down this complex task into smaller, manageable steps:\n",
        "          Task: {task}\n",
        "\n",
        "          Steps:\n",
        "          1)\"\"\"),\n",
        "        ]\n",
        ")\n",
        "\n",
        "def ltm_response(task):\n",
        "    # Get the Steps\n",
        "    ltm_chain = step_prompt | llm\n",
        "    steps = ltm_chain.invoke({\"task\": task}).content\n",
        "\n",
        "    # Now solve each step\n",
        "    solve_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "          (\"system\", \"You are an AI that can solve problems step by step.\"),\n",
        "          (\"human\", \"\"\"Solve each step of this task:\n",
        "            Task: {task}\n",
        "\n",
        "            Steps:\n",
        "            {steps}\n",
        "\n",
        "            Solutions:\"\"\"),\n",
        "        ]\n",
        "    )\n",
        "    solve_chain = solve_prompt | llm\n",
        "    response = solve_chain.invoke({\"task\": task, \"steps\": steps}).content\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "FToKQB7jLBYD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"Develop a machine learning model to predict stock prices\"\n",
        "response = ltm_response(task)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKcYN1U1yh2M",
        "outputId": "f0f81463-7c24-4ed1-b919-eb4e89a96291"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's go through each step and provide a solution.\n",
            "\n",
            "**Step 1:** Gather and preprocess the data\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Identify the stock market data sources: Yahoo Finance, Quandl, Alpha Vantage\n",
            "* Determine the specific stock(s) to focus on: Apple Inc. (AAPL)\n",
            "* Collect historical stock price data (daily closing prices) for the specified time period: 2010-2022\n",
            "* Preprocess the data by:\n",
            "\t+ Handling missing values: impute missing values with the previous day's closing price\n",
            "\t+ Normalizing/scaling the data: scale the data using Min-Max Scaler from Scikit-learn\n",
            "\t+ Converting data types: convert datetime to numeric using pandas' to_numeric function\n",
            "\t+ Feature engineering: calculate moving averages (MA) and relative strength index (RSI) using pandas' rolling and ewm functions\n",
            "\n",
            "**Step 2:** Split the data into training and testing sets\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Divide the preprocessed data into two sets:\n",
            "\t+ Training set (80% of the data): 2010-2018\n",
            "\t+ Testing set (20% of the data): 2019-2022\n",
            "\n",
            "**Step 3:** Choose a machine learning algorithm\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Research and select a suitable machine learning algorithm for stock price prediction: Long Short-Term Memory (LSTM) neural network\n",
            "* Consider factors such as:\n",
            "\t+ Complexity of the model: LSTM is suitable for modeling complex time-series data\n",
            "\t+ Computational resources required: LSTM requires significant computational resources, but can be parallelized\n",
            "\t+ Interpretability of the results: LSTM provides interpretable results, but may require additional feature engineering\n",
            "\n",
            "**Step 4:** Train the machine learning model\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Use the training set to train the LSTM neural network using Keras' Sequential API\n",
            "* Tune hyperparameters using Bayesian optimization with Optuna\n",
            "* Monitor the model's performance during training using mean absolute error (MAE) and mean squared error (MSE)\n",
            "\n",
            "**Step 5:** Evaluate the machine learning model\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Use the testing set to evaluate the performance of the trained LSTM model\n",
            "* Calculate metrics such as MAE, MSE, and R-squared to assess the model's accuracy\n",
            "* Visualize the predicted vs. actual stock prices using matplotlib and seaborn\n",
            "\n",
            "**Step 6:** Refine and iterate the model\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Refine the model by:\n",
            "\t+ Adjusting hyperparameters: adjust the number of LSTM layers, units, and dropout rate\n",
            "\t+ Adding or removing features: add or remove features such as moving averages and RSI\n",
            "\t+ Using techniques such as feature selection or dimensionality reduction: use PCA or t-SNE to reduce dimensionality\n",
            "* Iterate the process until the model achieves satisfactory performance: MAE < 1.5, MSE < 2.5\n",
            "\n",
            "**Step 7:** Deploy the machine learning model\n",
            "\n",
            "Solution:\n",
            "\n",
            "* Implement the trained LSTM model in a production-ready environment: use Flask or Django to create a web application\n",
            "* Set up monitoring and logging mechanisms: use Loggly or Splunk to track the model's performance in real-time\n",
            "* Integrate the model with other systems or tools as needed: integrate with a trading platform or a financial dashboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ja7ZCUY2MJT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}